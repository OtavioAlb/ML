{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto do Problema\n",
    "\n",
    "Dado o conjunto de dados de treinamento:\n",
    "\n",
    "$$\n",
    "X = \\Big\\{(x_1, y_1), (x_2, y_2), \\ldots, (x_N, y_N)\\Big\\},\n",
    "$$\n",
    "\n",
    "onde $\\mathbf{x}^{(i)} \\in \\mathbb{R}^{d}$ e $y^{(i)} \\in \\mathbb{R}$, $; i = 1, 2, \\ldots, N$, considere:\n",
    "\n",
    "\n",
    "\n",
    "- $\\mathbf{x} = (x_1, \\ldots, x_d) \\in \\mathbb{R}^d$, que representa os atributos das observações no espaço de entrada.\n",
    "- Adicionamos uma coordenada artificial $x_0 = 1$, tal que $\\tilde{\\mathbf{x}} = (1, x_1, \\ldots, x_d) \\in \\mathbb{R}^{1+d}$.\n",
    "\n",
    "Nosso objetivo é ajustar um modelo de **regressão linear** para prever os valores $y_i$ a partir de $\\mathbf{x}_i$, assumindo que a relação entre as variáveis $\\mathbf{x}$ e $y$ pode ser aproximada linearmente:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\mathbf{w}^T \\tilde{\\mathbf{x}},\n",
    "$$\n",
    "\n",
    "onde $\\mathbf{w} = (w_0, w_1, \\ldots, w_d) \\in \\mathbb{R}^{1+d}$ é o vetor de pesos.\n",
    "\n",
    "A função de custo a ser minimizada é o **Erro Quadrático Médio (MSE)**, dado por:\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N \\Big(y_i - \\hat{y}\\Big)^2.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivação da Função de Custo\n",
    "\n",
    "A função de custo da **regressão linear** é definida como o **Erro Quadrático Médio (MSE)**:\n",
    "\n",
    "$$\n",
    "J(\\mathbf{w}) = \\frac{1}{N} \\sum_{i=1}^N \\Big(y_i - \\hat{y}\\Big)^2.\n",
    "$$\n",
    "\n",
    "### Forma Vetorial\n",
    "\n",
    "Definimos:\n",
    "\n",
    "- $\\mathbf{X} \\in \\mathbb{R}^{N \\times (d+1)}$, sendo a matriz de atributos com coordenada artificial $1$ adicionada:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} =\n",
    "\\begin{bmatrix}\n",
    "1 & x_{11} & x_{12} & \\cdots & x_{1d} \\\\\n",
    "1 & x_{21} & x_{22} & \\cdots & x_{2d} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "1 & x_{N1} & x_{N2} & \\cdots & x_{Nd}\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "- $\\mathbf{y} \\in \\mathbb{R}^N$, sendo o vetor com os valores observados $y_i$:\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_N\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "- $\\mathbf{w} \\in \\mathbb{R}^{d+1}$, sendo o vetor de pesos.\n",
    "\n",
    "Expandindo a fórmula:\n",
    "\n",
    "$$\n",
    "J(\\mathbf{w}) = \\frac{1}{N} (\\mathbf{y} - \\mathbf{X}\\mathbf{w})^T (\\mathbf{y} - \\mathbf{X}\\mathbf{w}).\n",
    "$$\n",
    "\n",
    "### Gradiente da Função de Custo\n",
    "\n",
    "Para minimizar $J(\\mathbf{w})$, calculamos o gradiente em relação a $\\mathbf{w}$:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = \\frac{2}{N} (\\mathbf{X}^{T}\\mathbf{y} -\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{w}} J(\\mathbf{w}) = -\\frac{2}{N} \\mathbf{X}^T (\\mathbf{y} - \\mathbf{X}\\mathbf{w}).\n",
    "$$\n",
    "\n",
    "### Condição de Otimalidade\n",
    "\n",
    "Para encontrar o mínimo, igualamos o gradiente a zero:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{w}} J(\\mathbf{w}) = 0.\n",
    "$$\n",
    "\n",
    "Portanto:\n",
    "\n",
    "$$\n",
    "-\\frac{2}{N} \\mathbf{X}^T (\\mathbf{y} - \\mathbf{X}\\mathbf{w}) = 0.\n",
    "$$\n",
    "\n",
    "Simplificando:\n",
    "\n",
    "$$\n",
    "\\mathbf{X}^T (\\mathbf{y} - \\mathbf{X}\\mathbf{w}) = 0.\n",
    "$$\n",
    "\n",
    "Distribuímos o produto interno:\n",
    "\n",
    "$$\n",
    "\\mathbf{X}^T\\mathbf{y} - \\mathbf{X}^T\\mathbf{X}\\mathbf{w} = 0.\n",
    "$$\n",
    "\n",
    "Reorganizamos para isolar $\\mathbf{w}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{X}^T\\mathbf{y} = \\mathbf{X}^T\\mathbf{X}\\mathbf{w}.\n",
    "$$\n",
    "\n",
    "Multiplicamos ambos os lados pela inversa de $\\mathbf{X}^T\\mathbf{X}$ (assumindo que $\\mathbf{X}^T\\mathbf{X}$ é invertível):\n",
    "\n",
    "$$\n",
    "\\mathbf{w} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praticando..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de Treinamento\n",
    "\n",
    "- O espaço de entrada será representado por $\\mathbb{R}^1$, ou seja, uma linha reta onde cada ponto é descrito por um número real: $\\mathbf{x}$.\n",
    "- Nosso conjunto de dados conterá $N$ pontos distribuídos no intervalo $[0, 2] \\subseteq \\mathbb{R}^1$.\n",
    "- O valor $y$ de cada ponto será calculado por uma função linear com ruído adicionado:\n",
    "\n",
    "$$\n",
    "y = f(x) + \\epsilon,\n",
    "$$\n",
    "\n",
    "onde \n",
    "\n",
    "$$\n",
    "f(x) = w_0 + wx\n",
    "$$\n",
    "\n",
    "e $\\epsilon$ é um termo de ruído gaussiano $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$.\n",
    "\n",
    "---\n",
    "\n",
    "### Ilustração\n",
    "\n",
    "- Traçaremos um gráfico com os dados de treinamento, onde os valores reais $y_i$ serão representados por **pontos** e a predição $\\hat{y}_i$ pelo modelo será representada por uma **linha contínua**.\n",
    "- A linha ajustada representará a melhor aproximação linear aos dados, obtida minimizando o erro quadrático médio.\n",
    "\n",
    "---\n",
    "\n",
    "### Exercício\n",
    "\n",
    "1. Gere $N$ pontos de treinamento $(x, y)$ de forma aleatória dentro do intervalo $[0, 2]$.\n",
    "2. Ajuste o modelo de regressão linear $\\hat{y} = \\mathbf{w}^T \\tilde{\\mathbf{x}}$ onde $\\tilde{\\mathbf{x}} = (1, x)$ inclui o termo $1$ como coordenada artificial.\n",
    "\n",
    "3. Plote:\n",
    "    - Os pontos de treinamento $(x, y)$ como pontos dispersos no gráfico.\n",
    "    - A linha de regressão ajustada no mesmo gráfico.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição do array X:  (100,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 100  # Número de pontos\n",
    "w0 = np.asarray([[1.0],[2.0], [-1.5]]) # pesos\n",
    "sigma = 0.1  # Desvio padrão do ruído\n",
    "\n",
    "xmin = ymin = -1\n",
    "xmax = ymax = 2\n",
    "\n",
    "X = np.random.uniform(xmin, xmax, N) # Cria um array com dados aleatórios com N = 6 e d = 2.\n",
    "print(\"Distribuição do array X: \", X.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
